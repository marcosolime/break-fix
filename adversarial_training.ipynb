{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training\n",
    "A first approach to make the CNN model more robust to gradient-based adversarial attacks. <br>\n",
    "It consists of finetuning the pretrained model with both clean and adversarial examples. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import utils\n",
    "import random\n",
    "\n",
    "# reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset_folder = \"mri_brain_tumor\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=f'{dataset_folder}/Training', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=f'{dataset_folder}/Testing', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=1)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.1855, 0.1855, 0.1855])\n",
      "Std: tensor([0.1813, 0.1813, 0.1813])\n"
     ]
    }
   ],
   "source": [
    "#mean, std = utils.compute_mean_std(train_loader)\n",
    "mean, std = torch.tensor([0.1855]*3), torch.tensor([0.1813]*3) # precomputed, to save time\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation for training dataset with data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),     # Randomly flip the image horizontally\n",
    "    transforms.RandomRotation(10),         # Randomly rotate the image by 10 degrees\n",
    "    transforms.Resize((224, 224)),         # Resize the image to 224x224\n",
    "    transforms.ToTensor(),                 # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=mean, std=std)  # Normalize the image\n",
    "])\n",
    "\n",
    "# Transformation for testing dataset without data augmentation\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),         # Resize the image to 224x224\n",
    "    transforms.ToTensor(),                 # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=mean, std=std)  # Normalize the image\n",
    "])\n",
    "\n",
    "# Apply the transformations to the datasets\n",
    "train_dataset = datasets.ImageFolder(root=f'{dataset_folder}/Training', transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder(root=f'{dataset_folder}/Testing', transform=test_transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=1)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gnele\\AppData\\Local\\Temp\\ipykernel_2944\\435087753.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('weights/cnn.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 51476484\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device.\")\n",
    "\n",
    "model = utils.CNN(num_classes=4).to(device)\n",
    "#load weights\n",
    "model.load_state_dict(torch.load('weights/cnn.pth'))\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial train function\n",
    "Use both original and noisy images to train the model. <br>\n",
    "We also apply image augmentation techniques to make the model more robust to adversarial attacks. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adversarial_train(dataloader, model, device, num_epochs, optimizer, criterion, attack_function, attack_params):\n",
    "    \"\"\"\n",
    "    This function trains the model using adversarial training. It generates adversarial images using the attack function and then appends them to the original images.\n",
    "    Args:\n",
    "    - dataloader: the dataloader for the dataset\n",
    "    - model: the model to train\n",
    "    - device: the device to train on\n",
    "    - num_epochs: the number of epochs to train\n",
    "    - attack function: generates the adversarial images (can be fgsm or pgd)\n",
    "    - attack_params: method-specific parameters for the attack function (dictionary)\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        batch_loss = 0.0\n",
    "\n",
    "        #print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        for batch_idx, (images, labels) in enumerate(tqdm(dataloader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\")):\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            attack_images = attack_function(model, criterion, images, labels, device, **attack_params) #the first arguments are the same, the rest are the method-specific attack_params\n",
    "            #append the attack images to the images\n",
    "            images = torch.cat((images, attack_images), 0)\n",
    "            labels = torch.cat((labels, labels), 0)\n",
    "            \n",
    "            # apply data augmentation to the images\n",
    "            #transformed_images = torch.stack([transform(image.cpu()).to(device) for image in images])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Loss: {running_loss/len(dataloader):.4f}\")\n",
    "        running_loss = 0.0\n",
    "\n",
    "    print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM\n",
    "Let's train the model with FGSM adversarial examples. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gnele\\AppData\\Local\\Temp\\ipykernel_2944\\2610971626.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  robust_model.load_state_dict(torch.load('weights/cnn.pth'))\n",
      "Epoch [1/5]: 100%|██████████| 714/714 [01:38<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/5]: 100%|██████████| 714/714 [01:40<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/5]: 100%|██████████| 714/714 [01:41<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/5]: 100%|██████████| 714/714 [01:36<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]: 100%|██████████| 714/714 [01:33<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1148\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#define a new model\n",
    "robust_model = utils.CNN(num_classes=4).to(device)\n",
    "robust_model.load_state_dict(torch.load('weights/cnn.pth'))\n",
    "optimizer = optim.Adam(robust_model.parameters(), lr=0.0001)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "attack_function = utils.fgsm_attack\n",
    "attack_params = {\"epsilon\": 0.1}\n",
    "adversarial_train(train_loader, robust_model, device, 5, optimizer, criterion,\n",
    "                  attack_function, attack_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(robust_model.state_dict(),'weights/robust_fgsm.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------- EPSILON VALUE:  0.1  ---------\n",
      "\n",
      "ROBUST MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|█████████▋| 31/32 [00:06<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: \t0.95\n",
      "Adversarial accuaracy: \t0.96\n",
      "\n",
      "\n",
      "--------- EPSILON VALUE:  0.01  ---------\n",
      "\n",
      "ROBUST MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|█████████▋| 31/32 [00:06<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: \t0.96\n",
      "Adversarial accuaracy: \t0.70\n",
      "\n",
      "\n",
      "--------- EPSILON VALUE:  0.005  ---------\n",
      "\n",
      "ROBUST MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|█████████▋| 31/32 [00:06<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: \t0.95\n",
      "Adversarial accuaracy: \t0.75\n",
      "\n",
      "\n",
      "--------- EPSILON VALUE:  0.002  ---------\n",
      "\n",
      "ROBUST MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|█████████▋| 31/32 [00:06<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: \t0.96\n",
      "Adversarial accuaracy: \t0.79\n",
      "\n",
      "\n",
      "--------- EPSILON VALUE:  0.001  ---------\n",
      "\n",
      "ROBUST MODEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|█████████▋| 31/32 [00:06<00:00,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: \t0.96\n",
      "Adversarial accuaracy: \t0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon_values=[ 0.1, 0.01, 0.005, 0.002, 0.001]\n",
    "for eps in epsilon_values:\n",
    "    print(\"\\n\\n--------- EPSILON VALUE: \", eps, \" ---------\")\n",
    "    utils.compare_eval(robust_model,test_loader, criterion, device, attack_function=utils.fgsm_attack, attack_params={\"epsilon\": eps})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGD - Projected Gradient Descent\n",
    "A more advanced attack than FGSM, that still uses the gradient of the loss function to generate adversarial examples, but it applies multiple steps of small perturbations to the input image. <br>\n",
    "Since it works similarly to FGSM, we can use the same adversarial training approach to make the model more robust to PGD attacks, this time using the PGD adversarial examples. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gnele\\AppData\\Local\\Temp\\ipykernel_2944\\4225556008.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  robust_model_pdg.load_state_dict(torch.load('weights/cnn.pth'))\n",
      "Epoch [1/5]: 100%|██████████| 714/714 [03:30<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/5]: 100%|██████████| 714/714 [03:34<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/5]: 100%|██████████| 714/714 [03:31<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/5]: 100%|██████████| 714/714 [03:32<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]: 100%|██████████| 714/714 [03:28<00:00,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1415\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#define a new model\n",
    "robust_model_pdg = utils.CNN(num_classes=4).to(device)\n",
    "robust_model_pdg.load_state_dict(torch.load('weights/cnn.pth'))\n",
    "optimizer = optim.Adam(robust_model_pdg.parameters(), lr=0.0001)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "pgd = utils.pgd_attack\n",
    "pgd_params = {\"eps\":0.01, \"alpha\":0.001, \"num_iter\":5}\n",
    "adversarial_train(train_loader, robust_model_pdg, device, 5, optimizer, criterion,\n",
    "                  pgd, pgd_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save/load weights\n",
    "torch.save(robust_model_pdg.state_dict(),'weights/robust_pgd.pth')\n",
    "#robust_model_pdg.load_state_dict(torch.load('weights/robust_pgd.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate PGD\n",
    "Keeping epsilon constant to 0.01, changing alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------- ALPHA VALUE:  0.001  ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|█████████▋| 31/32 [00:11<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: \t0.97\n",
      "Adversarial accuaracy: \t0.91\n",
      "\n",
      "\n",
      "--------- ALPHA VALUE:  0.0005  ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|█████████▋| 31/32 [00:11<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: \t0.97\n",
      "Adversarial accuaracy: \t0.95\n",
      "\n",
      "\n",
      "--------- ALPHA VALUE:  0.0001  ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|█████████▋| 31/32 [00:11<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: \t0.98\n",
      "Adversarial accuaracy: \t0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alphas=[0.001, 0.0005, 0.0001]\n",
    "for alpha in alphas:\n",
    "    print(\"\\n\\n--------- ALPHA VALUE: \", alpha, \" ---------\")\n",
    "    utils.compare_eval(robust_model_pdg,test_loader, criterion, device, attack_function=utils.pgd_attack, attack_params={\"eps\":0.01, \"alpha\":alpha, \"num_iter\":5})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross evaluations\n",
    "Let's evaluate the model trained with FGSM adversarial examples using PGD adversarial examples, and vice-versa. <br>\n",
    "This way we can see how the techniques generalize to different types of adversarial attacks. <br>\n",
    "Each version has its pros and cons:\n",
    "- FGSM is faster to compute, but less effective than PGD.\n",
    "- PGD is more effective, but slower to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate FGSM using the PGD-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------- EPSILON VALUE:  0.1  ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|█████████▋| 31/32 [00:06<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: \t0.95\n",
      "Adversarial accuaracy: \t0.54\n",
      "\n",
      "\n",
      "--------- EPSILON VALUE:  0.01  ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|█████████▋| 31/32 [00:06<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: \t0.95\n",
      "Adversarial accuaracy: \t0.91\n",
      "\n",
      "\n",
      "--------- EPSILON VALUE:  0.005  ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|█████████▋| 31/32 [00:06<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: \t0.94\n",
      "Adversarial accuaracy: \t0.88\n",
      "\n",
      "\n",
      "--------- EPSILON VALUE:  0.002  ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|█████████▋| 31/32 [00:06<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: \t0.96\n",
      "Adversarial accuaracy: \t0.92\n",
      "\n",
      "\n",
      "--------- EPSILON VALUE:  0.001  ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|█████████▋| 31/32 [00:06<00:00,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: \t0.96\n",
      "Adversarial accuaracy: \t0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fgsm=utils.fgsm_attack\n",
    "epsilon_values=[0.1, 0.01, 0.005, 0.002, 0.001]\n",
    "for eps in epsilon_values:\n",
    "    print(\"\\n\\n--------- EPSILON VALUE: \", eps, \" ---------\")\n",
    "    utils.compare_eval(robust_model_pdg,test_loader, criterion, device, fgsm, attack_params={\"epsilon\": eps})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate PGD using the FGSM-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------- ALPHA VALUE:  0.001  ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|█████████▋| 31/32 [00:11<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: \t0.96\n",
      "Adversarial accuaracy: \t0.73\n",
      "\n",
      "\n",
      "--------- ALPHA VALUE:  0.0005  ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|█████████▋| 31/32 [00:11<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: \t0.96\n",
      "Adversarial accuaracy: \t0.75\n",
      "\n",
      "\n",
      "--------- ALPHA VALUE:  0.0001  ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|█████████▋| 31/32 [00:11<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy: \t0.96\n",
      "Adversarial accuaracy: \t0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alphas=[0.001, 0.0005, 0.0001]\n",
    "for alpha in alphas:\n",
    "    print(\"\\n\\n--------- ALPHA VALUE: \", alpha, \" ---------\")\n",
    "    utils.compare_eval(robust_model,test_loader, criterion, device, attack_function=utils.pgd_attack, attack_params={\"eps\":0.01, \"alpha\":alpha, \"num_iter\":5})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "break-fix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
