{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern detector ðŸ‘€\n",
    "- We artificially manipulate a dataset with **adversarial patterns** and train a robust classifier to detect these alterations. Since are we unaware of the kind of patterns and location in the images, we handcraft inject several of them in random positions. We train a pre-trained ResNet18 model on a binary classification task (*poisoned/non-poisoned*), and assess its performance on the test set, poisoned in a similar manner.\n",
    "- This simple yet efficient model could be placed in **early stages** of the classification pipeline, filtering out potential anomalies before time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "from random import randint\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriggerPatternDataset(Dataset):\n",
    "    def __init__(self, dataset, trigger_ratio=0.5, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.trigger_ratio = trigger_ratio\n",
    "        self.transform = transform\n",
    "\n",
    "        # we decide upfront the indices of the images to be poisoned\n",
    "        self.triggered_indices = np.random.choice(len(dataset), size=int(len(dataset) * trigger_ratio), replace=False)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, _ = self.dataset[idx]\n",
    "        image = np.array(image)\n",
    "\n",
    "        if idx in self.triggered_indices:\n",
    "            image = self.add_trigger(image, hash(idx))\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "    def add_trigger(self, image, seed, pattern_type=\"random\", brigthness=0.5):\n",
    "        intensity = int(255 * brigthness)\n",
    "        color = (intensity, intensity, intensity)\n",
    "        h, w, _ = image.shape\n",
    "        random.seed(seed)\n",
    "        \n",
    "        if pattern_type == \"random\":\n",
    "            pattern_type = random.choice([\"circle\", \"square\", \"cross\", \"triangle\"])\n",
    "\n",
    "        if pattern_type == \"circle\":\n",
    "            size = randint(3, 6)\n",
    "            center = randint(0, w), randint(0, h)\n",
    "            cv2.circle(image, center, size, color, -1)\n",
    "        \n",
    "        elif pattern_type == \"square\":\n",
    "            size = randint(5, 10)\n",
    "            top = randint(0, w-size), randint(0, h-size)\n",
    "            bottom = top[0] + size, top[1] + size\n",
    "            cv2.rectangle(image, top, bottom, color, -1)\n",
    "        \n",
    "        elif pattern_type == \"cross\":\n",
    "            size = randint(5, 10)\n",
    "            x, y = randint(0, w-size), randint(0, h-size)\n",
    "            cv2.line(image, (x,y), (x+size, y+size), color, 2)\n",
    "            cv2.line(image, (x+size,y), (x,y+size), color, 2)\n",
    "\n",
    "        elif pattern_type == \"triangle\":\n",
    "            size = randint(5, 15)\n",
    "            base_x, base_y = randint(0, w-size), randint(0, h-size)\n",
    "            pt1 = (base_x, base_y)\n",
    "            pt2 = (base_x, base_y + size)\n",
    "            pt3 = (base_x + size, base_y + size)\n",
    "            triangle = np.array([pt1,pt2,pt3])\n",
    "            cv2.fillPoly(image, [triangle], (intensity, intensity, intensity))\n",
    "\n",
    "        return image\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we use Resnet18 trained on imagenet, to normalize out dataset we use the statistics of imagenet (mean and std)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"mri_brain_tumor\"\n",
    "\n",
    "train_data = ImageFolder(root=f'{dataset_folder}/Training', transform=None)\n",
    "test_data = ImageFolder(root=f'{dataset_folder}/Testing', transform=None)\n",
    "\n",
    "train_dataset = TriggerPatternDataset(train_data, transform=transform)\n",
    "test_dataset = TriggerPatternDataset(test_data, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch shape | images:[8, 3, 224, 224], labels: 8\n"
     ]
    }
   ],
   "source": [
    "# debug - sanity check\n",
    "for batch in train_loader:\n",
    "    images, labels = batch[0], batch[1]\n",
    "    print(f\"batch shape | images:{list(images.shape)}, labels: {len(batch[0])}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning ResNet18\n",
    "Now we fine tune a pre-trained ResNet18 model on our dataset to classify images based on the presence of trigger patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('using', device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 11.178 M\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params/(10**6):.3f} M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As loss we pick the Cross Entropy loss and as optimizer we use Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 started.\n",
      "[0/714]\n",
      "[32/714]\n",
      "[64/714]\n",
      "[96/714]\n",
      "[128/714]\n",
      "[160/714]\n",
      "[192/714]\n",
      "[224/714]\n",
      "[256/714]\n",
      "[288/714]\n",
      "[320/714]\n",
      "[352/714]\n",
      "[384/714]\n",
      "[416/714]\n",
      "[448/714]\n",
      "[480/714]\n",
      "[512/714]\n",
      "[544/714]\n",
      "[576/714]\n",
      "[608/714]\n",
      "[640/714]\n",
      "[672/714]\n",
      "[704/714]\n",
      "Epoch 1/5, Loss: 0.6262418848125875\n",
      "Epoch 1 started.\n",
      "[0/714]\n",
      "[32/714]\n",
      "[64/714]\n",
      "[96/714]\n",
      "[128/714]\n",
      "[160/714]\n",
      "[192/714]\n",
      "[224/714]\n",
      "[256/714]\n",
      "[288/714]\n",
      "[320/714]\n",
      "[352/714]\n",
      "[384/714]\n",
      "[416/714]\n",
      "[448/714]\n",
      "[480/714]\n",
      "[512/714]\n",
      "[544/714]\n",
      "[576/714]\n",
      "[608/714]\n",
      "[640/714]\n",
      "[672/714]\n",
      "[704/714]\n",
      "Epoch 2/5, Loss: 0.5444423077361924\n",
      "Epoch 2 started.\n",
      "[0/714]\n",
      "[32/714]\n",
      "[64/714]\n",
      "[96/714]\n",
      "[128/714]\n",
      "[160/714]\n",
      "[192/714]\n",
      "[224/714]\n",
      "[256/714]\n",
      "[288/714]\n",
      "[320/714]\n",
      "[352/714]\n",
      "[384/714]\n",
      "[416/714]\n",
      "[448/714]\n",
      "[480/714]\n",
      "[512/714]\n",
      "[544/714]\n",
      "[576/714]\n",
      "[608/714]\n",
      "[640/714]\n",
      "[672/714]\n",
      "[704/714]\n",
      "Epoch 3/5, Loss: 0.5175841012421776\n",
      "Epoch 3 started.\n",
      "[0/714]\n",
      "[32/714]\n",
      "[64/714]\n",
      "[96/714]\n",
      "[128/714]\n",
      "[160/714]\n",
      "[192/714]\n",
      "[224/714]\n",
      "[256/714]\n",
      "[288/714]\n",
      "[320/714]\n",
      "[352/714]\n",
      "[384/714]\n",
      "[416/714]\n",
      "[448/714]\n",
      "[480/714]\n",
      "[512/714]\n",
      "[544/714]\n",
      "[576/714]\n",
      "[608/714]\n",
      "[640/714]\n",
      "[672/714]\n",
      "[704/714]\n",
      "Epoch 4/5, Loss: 0.4608195224041198\n",
      "Epoch 4 started.\n",
      "[0/714]\n",
      "[32/714]\n",
      "[64/714]\n",
      "[96/714]\n",
      "[128/714]\n",
      "[160/714]\n",
      "[192/714]\n",
      "[224/714]\n",
      "[256/714]\n",
      "[288/714]\n",
      "[320/714]\n",
      "[352/714]\n",
      "[384/714]\n",
      "[416/714]\n",
      "[448/714]\n",
      "[480/714]\n",
      "[512/714]\n",
      "[544/714]\n",
      "[576/714]\n",
      "[608/714]\n",
      "[640/714]\n",
      "[672/714]\n",
      "[704/714]\n",
      "Epoch 5/5, Loss: 0.39578364642352615\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch} started.\")\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 32 == 0:\n",
    "            print(f\"[{i}/{len(train_loader)}]\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.3f}\")\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "We now evaluate the model on the test set and calculate metrics such as accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 164/164 [00:07<00:00, 21.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (il sangue)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "    \n",
    "    print(\"DONE (il sangue)\")\n",
    "    return y_true, y_pred\n",
    "\n",
    "y_true, y_pred = evaluate_model(model, test_loader)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='binary')\n",
    "recall = recall_score(y_true, y_pred, average='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.83      0.75       656\n",
      "           1       0.78      0.61      0.68       655\n",
      "\n",
      "    accuracy                           0.72      1311\n",
      "   macro avg       0.73      0.72      0.72      1311\n",
      "weighted avg       0.73      0.72      0.72      1311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
